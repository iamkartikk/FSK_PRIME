{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 6: Introduction to Video Processing with OpenCV"
      ],
      "metadata": {
        "id": "L982FdumDCVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup and Video Loading"
      ],
      "metadata": {
        "id": "gk9AwRFXDO6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 1**: Load and Display Video\n",
        "*Instruction*: Load a video file (`sample_video.mp4`) and display it frame-by-frame using OpenCV."
      ],
      "metadata": {
        "id": "tG2LLFb4DSrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # Important for Colab!\n",
        "\n",
        "# Load video\n",
        "cap = cv2.VideoCapture('sample_video.mp4')  # Make sure your file is uploaded\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Display frame using cv2_imshow for Colab\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Wait for 25 ms\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "G6YtbgenDSWH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Convert Frames to Grayscale"
      ],
      "metadata": {
        "id": "03CKwCBtDzRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Display Grayscale Video Frames\n",
        "\n",
        "*Instruction*: Convert each frame to grayscale before displaying.\n"
      ],
      "metadata": {
        "id": "oh1W_9m5DuzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cap = cv2.VideoCapture('sample_video.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    plt.imshow(gray, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "SQTsWR6GDn6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Save Processed Video"
      ],
      "metadata": {
        "id": "mVV1BgZvEE3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3**: Save Grayscale Video to File\n",
        "\n",
        "*Instruction*: Save the grayscale video to disk as `output_gray.avi`.\n"
      ],
      "metadata": {
        "id": "opUK7Z7LEIr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Open the input video\n",
        "cap = cv2.VideoCapture('sample_video.mp4')  # Replace with your input video filename\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "out = cv2.VideoWriter('output_gray.avi',\n",
        "                      cv2.VideoWriter_fourcc(*'XVID'),\n",
        "                      fps,\n",
        "                      (frame_width, frame_height),\n",
        "                      isColor=False)  # Set isColor=False for grayscale\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Open the input video\n",
        "cap = cv2.VideoCapture('sample_video.mp4')  # Replace with your input video filename\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "out = cv2.VideoWriter('output_gray.avi',\n",
        "                      cv2.VideoWriter_fourcc(*'XVID'),\n",
        "                      fps,\n",
        "                      (frame_width, frame_height),\n",
        "                      isColor=False)  # Set isColor=False for grayscale\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to grayscale\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Write the grayscale frame\n",
        "    out.write(gray_frame)\n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Grayscale video saved as 'output_gray.avi'\")\n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Grayscale video saved as 'output_gray.avi'\")\n"
      ],
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2d029f-749e-47cb-90bf-2ef14664a2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grayscale video saved as 'output_gray.avi'\n",
            "Grayscale video saved as 'output_gray.avi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Real-Time Webcam Feed"
      ],
      "metadata": {
        "id": "GNO0DPi3EpgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4**: Capture and Display Webcam Feed\n",
        "\n",
        "*Instruction*: Access the webcam and display the live video feed. Press `q` to quit."
      ],
      "metadata": {
        "id": "W74DNGaJEtdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q pyngrok\n",
        "\n",
        "# Import libraries\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to capture image from webcam\n",
        "def capture_image():\n",
        "    js = Javascript('''\n",
        "        async function captureImage() {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture button click\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            capture.remove();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', 0.8);\n",
        "        }\n",
        "        captureImage();\n",
        "    ''')\n",
        "\n",
        "    display(js)\n",
        "    data = eval_js('captureImage()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    np_arr = np.frombuffer(binary, dtype=np.uint8)\n",
        "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "    return img\n",
        "\n",
        "# Now run the capture\n",
        "print(\"Click 'Capture' to take a photo ðŸ“¸\")\n",
        "img = capture_image()\n",
        "\n",
        "\n",
        "# Show the captured image\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title('Captured Image')\n",
        "plt.show()\n",
        "if cv2.waitKey(1) & 0xFF == ord('q'): # The condition to check if 'q' is pressed\n",
        "    # Optionally, save the captured image, This code block will only run if 'q' is pressed\n",
        "    cv2.imwrite('captured_image.jpg', img)\n",
        "    print(\"âœ… Image saved as captured_image.jpg\")"
      ],
      "metadata": {
        "id": "aM8iWEAXEOmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5: Add Live Effects to Webcam Feed"
      ],
      "metadata": {
        "id": "yFxPFagsE9mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 5**:  Apply Canny Edge Detection in Real-Time\n",
        "\n",
        "*Instruction*: While capturing from webcam, apply Canny edge detection to each frame and display side-by-side.\n"
      ],
      "metadata": {
        "id": "IZwIOzHXFD1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import necessary libraries\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 2. Function to capture webcam image\n",
        "def capture_frame():\n",
        "    js = Javascript('''\n",
        "    async function captureFrame() {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        const video = document.createElement('video');\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Resize the output to fit\n",
        "        video.style.width = '400px';\n",
        "\n",
        "        div.appendChild(video);\n",
        "\n",
        "        // Wait for Capture button click\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "    captureFrame();\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('captureFrame()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    np_arr = np.frombuffer(binary, dtype=np.uint8)\n",
        "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "    return img\n",
        "\n",
        "# 3. Capture a frame\n",
        "frame = capture_frame()\n",
        "\n",
        "# 4. Apply Canny edge detection\n",
        "edges = cv2.Canny(frame, 100, 200)\n",
        "\n",
        "# 5. Stack images side-by-side\n",
        "combined = np.hstack((frame, cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)))\n",
        "\n",
        "# 6. Show the result\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(combined)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "VpUFTR1JFDWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 6: Color Spaces and Histogram"
      ],
      "metadata": {
        "id": "w-OY1jI5IaIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 6**: Convert Color Spaces and Plot Histogram\n",
        "\n",
        "*Instruction*: Convert the image to grayscale and HSV. Then plot a histogram of grayscale values."
      ],
      "metadata": {
        "id": "xeBCcr3RIi-8"
      }
    },
    {
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image_path = 'sample.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "if image is None:\n",
        "    print(f\"Error: Could not load image from {image_path}. Please check the path and ensure the image file exists.\")\n",
        "else:\n",
        "    #  Convert to Grayscale and HSV\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # 3. Plot histogram of grayscale\n",
        "    plt.hist(gray.ravel(), bins=256, range=[0, 256])\n",
        "    plt.title(\"Grayscale Histogram\")\n",
        "    plt.xlabel(\"Pixel Intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7dmk7NAG2YIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}